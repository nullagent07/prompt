############################
# NETWORK / PROXY
############################

HTTP_PROXY=http://control2.nestro.ru:3128
HTTPS_PROXY=http://control2.nestro.ru:3128
NO_PROXY=localhost,127.0.0.1,::1,host.docker.internal,10.0.0.0/8

############################
# HUGGINGFACE
############################

HF_TOKEN=
HF_HOME=/models/hf_cache
TRANSFORMERS_CACHE=/models/hf_cache
HF_HUB_ENABLE_HF_TRANSFER=1

############################
# GPU / NVIDIA
############################

NVIDIA_VISIBLE_DEVICES=all
NVIDIA_DRIVER_CAPABILITIES=compute,utility
CUDA_VISIBLE_DEVICES=0

############################
# LLM (vLLM)
############################

LLM_MODEL=Qwen/Qwen2.5-14B-Instruct
LLM_PORT=8000

LLM_HOST=0.0.0.0
LLM_MAX_MODEL_LEN=8192
LLM_GPU_MEMORY_UTILIZATION=0.92
LLM_TENSOR_PARALLEL_SIZE=1
LLM_DTYPE=float16
LLM_MAX_NUM_BATCHED_TOKENS=8192
LLM_MAX_NUM_SEQS=256
LLM_TRUST_REMOTE_CODE=true

############################
# EMBEDDINGS (vLLM)
############################

EMBEDDING_MODEL=BAAI/bge-m3
EMBEDDING_PORT=8081

EMBEDDING_MAX_BATCH=128
EMBEDDING_GPU_MEMORY_UTILIZATION=0.25
EMBEDDING_DTYPE=float16

############################
# RERANKER (TEI)
############################

RERANK_MODEL=BAAI/bge-reranker-v2-m3
RERANK_PORT=8082

RERANK_MAX_BATCH=64
RERANK_MAX_LENGTH=1024

############################
# LITELLM (optional gateway)
############################

LITELLM_PORT=4000
LITELLM_MASTER_KEY=super-secret-master-key
LITELLM_LOG_LEVEL=INFO

############################
# QDRANT (remote)
############################

QDRANT_URL=http://10.0.0.5:6333
QDRANT_API_KEY=

############################
# PROMETHEUS
############################

PROMETHEUS_PORT=9090
PROMETHEUS_RETENTION_TIME=15d
PROMETHEUS_RETENTION_SIZE=20GB

############################
# GRAFANA
############################

GRAFANA_PORT=3000
GRAFANA_ADMIN_USER=admin
GRAFANA_ADMIN_PASSWORD=ChangeMeStrongPassword

############################
# DCGM EXPORTER (GPU metrics)
############################

DCGM_EXPORTER_PORT=9400

############################
# SYSTEM TUNING
############################

OMP_NUM_THREADS=16
UVICORN_WORKERS=1
TOKENIZERS_PARALLELISM=false
PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:512
